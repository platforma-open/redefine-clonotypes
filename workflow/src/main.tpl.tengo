// "Redefine clonotypes workflow"
wf := import("@platforma-sdk/workflow-tengo:workflow")
ll := import("@platforma-sdk/workflow-tengo:ll")
pt := import("@platforma-sdk/workflow-tengo:pt")
pframes := import("@platforma-sdk/workflow-tengo:pframes")
pSpec := import("@platforma-sdk/workflow-tengo:pframes.spec")
text := import("text")
slices := import("@platforma-sdk/workflow-tengo:slices")
maps := import("@platforma-sdk/workflow-tengo:maps")
xsv := import("@platforma-sdk/workflow-tengo:pframes.xsv")
canonical := import("@platforma-sdk/workflow-tengo:canonical")
json := import("json")

// --- Clonotype Label Generation (copied from MiXCR Clonotyping) ---
addClonotypeLabelColumnsPt := func(df, clonotypeKeyCol, clonotypeLabelCol) {
    prefixTempCol := clonotypeLabelCol + "_prefix_temp"
    rankTempCol := clonotypeLabelCol + "_rank_temp"

    df = df.withColumns(
        pt.col(clonotypeKeyCol).
            strReplace("\\d", "", { replaceAll: true }).
            strSlice(0, 5).
            strToUpper().
            alias(prefixTempCol)
    )

    df = df.withColumns(
        pt.rank(pt.col(clonotypeKeyCol)).
            over(pt.col(prefixTempCol)).
            alias(rankTempCol)
    )

    df = df.withColumns(
        pt.when(pt.col(rankTempCol).gt(pt.lit(1))).
            then(pt.concatStr([pt.lit("C"), pt.col(prefixTempCol), pt.col(rankTempCol).cast("String")], { delimiter: "-" })).
            otherwise(pt.concatStr([pt.lit("C"), pt.col(prefixTempCol)], { delimiter: "-" })).
            alias(clonotypeLabelCol)
    )

    return df.withoutColumns(prefixTempCol, rankTempCol)
}


wf.prepare(func(args) {
	bundleBuilder := wf.createPBundleBuilder()
	bundleBuilder.addAnchor("main", args.anchorRef)

	// Clonotype definition columns
	for i, colId in args.clonotypeDefinition {
		bundleBuilder.addSingle(colId, "clonotypeDefinition_" + i)
	}

	// All non-normalized abundance columns
	bundleBuilder.addMulti({
		axes: [{ anchor: "main", idx: 0 }, { anchor: "main", idx: 1 }],
		annotations: {
			"pl7.app/isAbundance": "true",
			"pl7.app/abundance/normalized": "false"
		}
	}, "abundances")

	// All clonotype property columns
	bundleBuilder.addMulti({
		axes: [{ anchor: "main", idx: 1 }]
	}, "properties")

	return {
		columns: bundleBuilder.build()
	}
})

wf.body(func(args) {
	columns := args.columns
	blockId := wf.blockId().getDataAsJson()

	abundanceCols := columns.getColumns("abundances")
	propertyCols := columns.getColumns("properties")
	
	clonotypeDefinitionCols := []
	for i, _ in args.clonotypeDefinition {
		clonotypeDefinitionCols = append(clonotypeDefinitionCols, columns.getColumn("clonotypeDefinition_" + i))
	}

	ll.assert(len(abundanceCols) > 0, "No abundance columns found in the dataset")

	mainAbundanceColIndex := -1
	for i, c in abundanceCols {
		if c.spec.annotations["pl7.app/abundance/isPrimary"] == "true" {
			mainAbundanceColIndex = i
			break
		}
	}
	ll.assert(mainAbundanceColIndex != -1, "No primary abundance column found")
	mainAbundanceCol := abundanceCols[mainAbundanceColIndex]

	sampleIdAxisSpec := mainAbundanceCol.spec.axesSpec[0]
	clonotypeKeyAxisSpec := mainAbundanceCol.spec.axesSpec[1]

	// --- Build the initial TSV for the pt workflow ---
	abundanceTsvBuilder := pframes.tsvFileBuilder()
	abundanceTsvBuilder.setAxisHeader(sampleIdAxisSpec, "sampleId")
	abundanceTsvBuilder.setAxisHeader(clonotypeKeyAxisSpec, "clonotypeKey")

	mainAbundanceHeader := "abundance_" + mainAbundanceColIndex
	
	abundanceHeaders := {}
	for i, col in abundanceCols {
		header := "abundance_" + i
		abundanceHeaders[header] = col
		abundanceTsvBuilder.add(col, { header: header })
	}
	
	definitionHeaders := []
	definitionLabels := []
	for i, col in clonotypeDefinitionCols {
		header := "clonotypeDefinition_" + i
		definitionHeaders = append(definitionHeaders, header)
		definitionLabels = append(definitionLabels, col.spec.annotations["pl7.app/label"])
		abundanceTsvBuilder.add(col, { header: header })
	}

	abundancesTsv := abundanceTsvBuilder.build()

	propertyTsvBuilder := pframes.tsvFileBuilder()
	propertyTsvBuilder.setAxisHeader(clonotypeKeyAxisSpec, "clonotypeKey")
	propertyHeaders := {}
	for i, col in propertyCols {
		header := "property_" + i
		propertyHeaders[header] = col
		propertyTsvBuilder.add(col, { header: header })
	}
	propertiesTsv := propertyTsvBuilder.build()

	
	// --- Define the entire data pipeline in a single pt workflow ---
	ptWf := pt.workflow()

	df := ptWf.frame(abundancesTsv, {xsvType: "tsv"})

	// 1. Calculate per-sample totals for each abundance column for normalization
	sampleTotalAggs := []
	totalColumnHeaders := []
	for header, _ in abundanceHeaders {
		totalHeader := header + "_total"
		sampleTotalAggs = append(sampleTotalAggs, pt.col(header).sum().alias(totalHeader))
		totalColumnHeaders = append(totalColumnHeaders, totalHeader)
	}
	sampleTotalsDf := df.groupBy("sampleId").agg(sampleTotalAggs...)

	// 2. Create the new clonotype definition string
	definitionColExprs := slices.map(definitionHeaders, func(h) { return pt.col(h) })
	dfWithNewKeyStr := df.withColumns(
		pt.
		  concatStr(definitionColExprs, {delimiter: "-"}).
		  hash("sha256", "base64_alphanumeric", 120).
		  alias("newClonotypeKey")
	)
	
	// 3. Calculate stats
	statsDf := dfWithNewKeyStr.select(
		pt.col("clonotypeKey").nUnique().alias("nClonotypesBefore"),
		pt.col("newClonotypeKey").nUnique().alias("nClonotypesAfter")
	)
	statsDf.saveContent("stats.tsv")

	// 4. Aggregate abundances
	abundanceAggs := []
	for h in maps.getKeys(abundanceHeaders) { 
		abundanceAggs = append(abundanceAggs, pt.col(h).sum().alias(h)) 
	}
	abundanceAggs = append(abundanceAggs, pt.col("clonotypeKey").maxBy(pt.col(mainAbundanceHeader)).alias("clonotypeKey"))
	df_abundances := dfWithNewKeyStr.groupBy("sampleId", "newClonotypeKey").agg(abundanceAggs...)

	// 8. Per-sample normalization
	df_abundances = df_abundances.join(sampleTotalsDf, {on: "sampleId", how: "left"})

	normExpressions := []
	for header, _ in abundanceHeaders {
		normExpressions = append(normExpressions, 
			pt.col(header).truediv(pt.col(header + "_total")).alias("normalized_" + header)
		)
	}
	df_abundances = df_abundances.withColumns(normExpressions...)
	df_abundances.save("abundances.tsv")

	// 5. Get representative properties
	
	// label clonotype key
	
	df_properties := df_abundances.join(ptWf.frame(propertiesTsv, {xsvType: "tsv"}), {on: "clonotypeKey", how: "left"})
	df_properties = addClonotypeLabelColumnsPt(df_properties, "newClonotypeKey", "clonotypeLabel")

	aggExpressions := [
		pt.col("clonotypeLabel").maxBy(pt.col(mainAbundanceHeader)).alias("clonotypeLabel")
	]
	for h, _ in propertyHeaders {
		aggExpressions = append(aggExpressions,
			pt.col(h).maxBy(pt.col(mainAbundanceHeader)).alias(h)
		)
	}
	aggregatedDf := df_properties.groupBy("newClonotypeKey").agg(aggExpressions...)
	aggregatedDf.save("properties.tsv")
	
	// --- Run and process ---
	ptResult := ptWf.run()
	finalAbundancesTsv := ptResult.getFile("abundances.tsv")
	finalPropertiesTsv := ptResult.getFile("properties.tsv")
	statsTsvContent := ptResult.getFileContent("stats.tsv")


	// --- Construct specs ---
	datasetSpec := columns.getSpec(args.anchorRef)
	trace := pSpec.makeTrace(datasetSpec, {
		type: "milaboratories.redefine-clonotypes",
		importance: 30,
		label: "Redefined Clonotypes: " + text.join(definitionLabels, "-")
	})

	newClonotypeKeySpec := maps.clone(clonotypeKeyAxisSpec)
	newClonotypeKeySpec.domain = maps.merge(newClonotypeKeySpec.domain, {
		"pl7.app/redefined-by": blockId,
		"pl7.app/vdj/clonotypeKey/structure": text.join(definitionLabels, "-") // override structure
	})

	abundanceAxes := [
		{
			column: "sampleId",	
			spec: sampleIdAxisSpec
		},
		{
			column: "newClonotypeKey",
			spec: newClonotypeKeySpec
		}
	]
	
	newAbundanceColumns := []
	for header, col in abundanceHeaders {
		newSpecUnnormalized := maps.clone(col.spec)
		delete(newSpecUnnormalized, "axesSpec")

		newAbundanceColumns = append(newAbundanceColumns, { 
			column: header, 
			id: header,
			spec: newSpecUnnormalized 
		})

		newSpecNormalized := maps.clone(newSpecUnnormalized)
		unit := newSpecNormalized.annotations["pl7.app/abundance/unit"]
		normalizedLabel := unit == "molecules" ? "UMI Fraction" : unit == "reads" ? "Read Fraction" : "Normalized Abundance"
		
		// Set normalized-specific spec name
		normalizedSpecName := unit == "molecules" ? "pl7.app/vdj/uniqueMoleculeFraction" : unit == "reads" ? "pl7.app/vdj/readFraction" : newSpecNormalized.name + "Normalized"
		newSpecNormalized.name = normalizedSpecName
		
		// Set normalized-specific annotations
		normalizedAnnotations := {
			"pl7.app/abundance/normalized": "true",
			"pl7.app/label": normalizedLabel,
			"pl7.app/min": "0",
			"pl7.app/max": "1",
			"pl7.app/format": ".2p"
		}
		
		// Preserve table visibility if it exists, otherwise set to optional
		if is_undefined(newSpecNormalized.annotations["pl7.app/table/visibility"]) {
			normalizedAnnotations["pl7.app/table/visibility"] = "optional"
		}
		
		newSpecNormalized.annotations = maps.merge(newSpecNormalized.annotations, normalizedAnnotations)
		if (newSpecNormalized.annotations["pl7.app/isAnchor"] == "true") {
			delete(newSpecNormalized.annotations, "pl7.app/isAnchor")
		}
		newSpecNormalized.valueType = "Double"
		
		normalizedHeader := "normalized_" + header
		newAbundanceColumns = append(newAbundanceColumns, { 
			column: normalizedHeader, 
			id: normalizedHeader,
			spec: newSpecNormalized 
		})
	}

	abundancePf := xsv.importFile(finalAbundancesTsv, "tsv", {
		axes: abundanceAxes,
		columns: newAbundanceColumns,
		storageFormat: "Parquet",
		partitionKeyLength: 1
	}, { splitDataAndSpec: true })

	propertyAxes := [
		{
			column: "newClonotypeKey",
			spec: newClonotypeKeySpec
		}
	]
	
	newPropertyColumns := [{
		column: "clonotypeLabel",
		spec: {
			name: "pl7.app/label",
			valueType: "String",
			annotations: {"pl7.app/label": "Clonotype Label"}
		}
	}]

	for header, col in propertyHeaders {
		newSpec :=	maps.clone(col.spec)
		delete(newSpec, "axesSpec")

		newPropertyColumns = append(newPropertyColumns, { column: header, spec: newSpec })
	}

	propertyPf := xsv.importFile(finalPropertiesTsv, "tsv", {
		axes: propertyAxes,
		columns: newPropertyColumns,
		storageFormat: "Parquet",
		partitionKeyLength: 0
	}, { splitDataAndSpec: true })
	

	pfBuilder := pframes.pFrameBuilder()
	for k, v in abundancePf {
		pfBuilder.add(k, trace.inject(v.spec), v.data)
	}
	for k, v in propertyPf {
		pfBuilder.add(k, trace.inject(v.spec), v.data)
	}
	finalPf := pfBuilder.build()

	return {
		outputs: {
			statsTsvContent: statsTsvContent
		},
		exports: {
			pf: finalPf
		}
	}
})
